<p>You have ssh access to nodes in your running job(s) .&nbsp; A couple basic monitoring tools are demonstrated in the example transcript here.&nbsp; Screen shots are appended so that you can see the output from the tools.&nbsp; Most common linux utilities are available from the compute nodes (free, strace, ps ...).</p><ac:structured-macro ac:name="code" ac:schema-version="1" ac:macro-id="386f16e0-56b5-4cb8-87d5-151204a83480"><ac:plain-text-body><![CDATA[[arnoldg@dt-login03 python]$ squeue -u $USER
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           1214412 gpuA40x4- interact  arnoldg  R       8:14      1 gpub045
[arnoldg@dt-login03 python]$ ssh gpub045
gpub045.delta.internal.ncsa.edu (141.142.145.145)
  OS: RedHat 8.4   HW: HPE   CPU: 64x    RAM: 252 GB
Last login: Wed Dec 14 09:45:26 2022 from 141.142.144.42
[arnoldg@gpub045 ~]$ nvidia-smi

[arnoldg@gpub045 ~]$ module load nvtop
---------------------------------------------------------------------------------------------------------------------
The following dependent module(s) are not currently loaded: cuda/11.6.1 (required by: ucx/1.11.2, openmpi/4.1.2)
---------------------------------------------------------------------------------------------------------------------

The following have been reloaded with a version change:
1) cuda/11.6.1 => cuda/11.7.0

[arnoldg@gpub045 ~]$ nvtop

[arnoldg@gpub045 ~]$ module load anaconda3_gpu
[arnoldg@gpub045 ~]$ nvitop

[arnoldg@gpub045 ~]$ top -u $USER
]]></ac:plain-text-body></ac:structured-macro>
<p>nvidia-smi :</p>
<p><ac:image><ri:attachment ri:filename="nvidia-smi.png" /></ac:image></p>
<p>nvtop :</p>
<p><ac:image><ri:attachment ri:filename="nvtop.png" /></ac:image></p>
<p>nvitop :</p>
<p><ac:image><ri:attachment ri:filename="nvitop.png" /></ac:image></p>
<p>top -u $USER :</p>
<p><ac:image><ri:attachment ri:filename="top.png" /></ac:image></p>
<p><br /></p>~
